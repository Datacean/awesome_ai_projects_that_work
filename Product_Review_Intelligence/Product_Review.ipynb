{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d4ac1b",
   "metadata": {},
   "source": [
    "# üéØ Product Review Intelligence System\n",
    "\n",
    "## Complete Step-by-Step Guide\n",
    "\n",
    "Welcome! This notebook will teach you how to build an intelligent system that automatically analyzes product reviews. By the end, you'll understand:\n",
    "\n",
    "1. **What problem we're solving** - Why manual review analysis is challenging\n",
    "2. **How AI models work** - The magic behind sentiment analysis and topic detection\n",
    "3. **How to build an API** - Making your solution accessible to others\n",
    "4. **Real-world examples** - Testing with actual Amazon reviews\n",
    "\n",
    "### What Makes This Special?\n",
    "\n",
    "This system can automatically:\n",
    "- üòäüòû Detect if a review is positive or negative (sentiment)\n",
    "- üè∑Ô∏è Identify what topics are mentioned (quality, shipping, price, etc.)\n",
    "- ‚ö° Flag reviews that need urgent attention\n",
    "- üöÄ Process reviews at scale through an API\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19daa3e4",
   "metadata": {},
   "source": [
    "## üì¶ Part 1: Installation & Setup\n",
    "\n",
    "First, we need to install the required libraries. Let's understand what each one does:\n",
    "\n",
    "- **transformers** ü§ñ - Hugging Face library with pre-trained AI models\n",
    "- **torch** üî• - PyTorch, the underlying machine learning framework\n",
    "- **fastapi** ‚ö° - Modern framework to build APIs quickly\n",
    "- **uvicorn** ü¶Ñ - Server to run our FastAPI application\n",
    "- **datasets** üìä - Access to thousands of datasets (we'll use Amazon reviews)\n",
    "- **requests** üåê - Make HTTP requests to test our API\n",
    "\n",
    "Run the cell below to install everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Note: This may take a few minutes the first time\n",
    "!pip install -q transformers torch fastapi uvicorn datasets requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll use\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2317a",
   "metadata": {},
   "source": [
    "## ü§ñ Part 2: Understanding AI Models\n",
    "\n",
    "### What is a Pre-trained Model?\n",
    "\n",
    "Think of a pre-trained model like a student who has already studied for years. Instead of teaching from scratch, we use models that have already learned from millions of text examples.\n",
    "\n",
    "We'll use **three different AI models**, each specialized for different tasks:\n",
    "\n",
    "### Model 1: Sentiment Analysis (DistilBERT)\n",
    "- **What it does**: Tells us if text is POSITIVE or NEGATIVE\n",
    "- **Model**: `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "- **Why this one**: Fast, accurate, trained on movie reviews (works great for product reviews too!)\n",
    "\n",
    "### Model 2: Zero-Shot Classification (BART)\n",
    "- **What it does**: Can classify text into ANY categories without specific training\n",
    "- **Model**: `facebook/bart-large-mnli`\n",
    "- **Why this one**: Flexible - we can detect topics and urgency with the same model\n",
    "- **\"Zero-shot\"** means we can give it new categories on the fly!\n",
    "\n",
    "Let's load these models and see them in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4315fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Sentiment Analysis model...\")\n",
    "print(\"(This downloads the model the first time - may take 1-2 minutes)\")\n",
    "\n",
    "# Load sentiment analyzer\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Sentiment model loaded!\")\n",
    "print(f\"Model type: {type(sentiment_analyzer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c90da",
   "metadata": {},
   "source": [
    "### üß™ Let's Test the Sentiment Model!\n",
    "\n",
    "Try it with some example reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cab052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different reviews\n",
    "test_reviews = [\n",
    "    \"This product is amazing! Best purchase I've made all year!\",\n",
    "    \"Terrible quality. Broke after one day. Don't waste your money.\",\n",
    "    \"It's okay, nothing special but does the job.\"\n",
    "]\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    result = sentiment_analyzer(review)[0]\n",
    "    print(f\"\\nüìù Review {i}: {review}\")\n",
    "    print(f\"   Sentiment: {result['label']} (confidence: {result['score']:.2%})\")\n",
    "    \n",
    "    # Add emoji for fun\n",
    "    emoji = \"üòä\" if result['label'] == \"POSITIVE\" else \"üòû\"\n",
    "    print(f\"   {emoji} {result['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd378a",
   "metadata": {},
   "source": [
    "### Now Load the Zero-Shot Classification Model\n",
    "\n",
    "This model is like a super-flexible classifier - we can ask it to classify text into ANY categories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Zero-Shot Classification model...\")\n",
    "print(\"(This is larger - may take 2-3 minutes to download)\")\n",
    "\n",
    "# Load zero-shot classifier\n",
    "topic_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Zero-shot classifier loaded!\")\n",
    "print(\"This model can classify ANY text into ANY categories we define!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa78728",
   "metadata": {},
   "source": [
    "### üß™ Test Zero-Shot Classification for Topics\n",
    "\n",
    "Let's detect what aspects of a product are mentioned in a review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the topics we want to detect\n",
    "TOPICS = [\n",
    "    \"product quality\",\n",
    "    \"shipping and delivery\", \n",
    "    \"price and value\",\n",
    "    \"customer service\",\n",
    "    \"packaging\"\n",
    "]\n",
    "\n",
    "# Test review that mentions multiple aspects\n",
    "test_review = \"Great product quality but the shipping was slow and the price seems a bit high for what you get.\"\n",
    "\n",
    "# Classify the review (multi_label=True means multiple topics can be detected)\n",
    "result = topic_classifier(\n",
    "    test_review,\n",
    "    candidate_labels=TOPICS,\n",
    "    multi_label=True\n",
    ")\n",
    "\n",
    "print(f\"üìù Review: {test_review}\\n\")\n",
    "print(\"üè∑Ô∏è  Detected Topics:\")\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    # Only show topics with confidence > 50%\n",
    "    if score > 0.5:\n",
    "        bar = \"‚ñà\" * int(score * 20)  # Visual bar\n",
    "        print(f\"   {label:25} {score:.1%} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ad1200",
   "metadata": {},
   "source": [
    "### üö® Detecting Urgency\n",
    "\n",
    "We can use the same model to detect if a review needs urgent attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d687d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define urgency labels\n",
    "URGENCY_LABELS = [\"urgent response needed\", \"routine feedback\"]\n",
    "\n",
    "# Test with different reviews\n",
    "urgent_review = \"This product is broken and I need a replacement ASAP! I have an important event tomorrow!\"\n",
    "routine_review = \"Nice product, works as expected. Happy with my purchase.\"\n",
    "\n",
    "for review_text in [urgent_review, routine_review]:\n",
    "    result = topic_classifier(\n",
    "        review_text,\n",
    "        candidate_labels=URGENCY_LABELS,\n",
    "        multi_label=False  # Only one label (either urgent or routine)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìù Review: {review_text}\")\n",
    "    print(f\"   Classification: {result['labels'][0]}\")\n",
    "    print(f\"   Confidence: {result['scores'][0]:.1%}\")\n",
    "    \n",
    "    if result['labels'][0] == \"urgent response needed\":\n",
    "        print(\"   ‚ö° ACTION REQUIRED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad63cc2",
   "metadata": {},
   "source": [
    "## üîß Part 3: Building the Complete Analysis Function\n",
    "\n",
    "Now let's combine everything into one powerful function that analyzes a review completely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_review(review_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze a single review for sentiment, topics, and urgency\n",
    "    \n",
    "    Returns a dictionary with:\n",
    "    - sentiment: \"positive\" or \"negative\"\n",
    "    - sentiment_confidence: how confident the model is (0-1)\n",
    "    - topics: list of detected topics with confidence scores\n",
    "    - needs_urgent_response: True/False\n",
    "    - urgency_confidence: how confident the model is about urgency\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Analyze Sentiment\n",
    "    # Truncate to 512 tokens (model limit)\n",
    "    sentiment_result = sentiment_analyzer(review_text[:512])[0]\n",
    "    sentiment = sentiment_result['label'].lower()\n",
    "    sentiment_score = sentiment_result['score']\n",
    "    \n",
    "    # 2. Detect Topics/Aspects\n",
    "    topic_result = topic_classifier(\n",
    "        review_text[:512],\n",
    "        candidate_labels=TOPICS,\n",
    "        multi_label=True  # Can detect multiple topics\n",
    "    )\n",
    "    \n",
    "    # Filter topics with confidence > 50%\n",
    "    relevant_topics = [\n",
    "        {\"topic\": label, \"confidence\": score}\n",
    "        for label, score in zip(topic_result['labels'], topic_result['scores'])\n",
    "        if score > 0.5\n",
    "    ]\n",
    "    \n",
    "    # 3. Detect Urgency\n",
    "    urgency_result = topic_classifier(\n",
    "        review_text[:512],\n",
    "        candidate_labels=URGENCY_LABELS,\n",
    "        multi_label=False  # Only one classification\n",
    "    )\n",
    "    \n",
    "    needs_response = urgency_result['labels'][0] == \"urgent response needed\"\n",
    "    urgency_score = urgency_result['scores'][0] if needs_response else 1 - urgency_result['scores'][0]\n",
    "    \n",
    "    # Return everything in a clean dictionary\n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"sentiment_confidence\": round(sentiment_score, 3),\n",
    "        \"topics\": relevant_topics,\n",
    "        \"needs_urgent_response\": needs_response,\n",
    "        \"urgency_confidence\": round(urgency_score, 3),\n",
    "        \"review_text\": review_text\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Analysis function created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635fb30",
   "metadata": {},
   "source": [
    "### üß™ Test the Complete Analysis Function\n",
    "\n",
    "Let's test it with various types of reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb544ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Test with different types of reviews\n",
    "test_cases = [\n",
    "    \"Amazing product! Worth every penny. Fast shipping and great quality.\",\n",
    "    \"Terrible experience. Product broke immediately and customer service won't respond. NEED HELP ASAP!\",\n",
    "    \"Good quality but overpriced. Took 3 weeks to arrive which was disappointing.\",\n",
    "]\n",
    "\n",
    "for i, review in enumerate(test_cases, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TEST CASE {i}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    result = analyze_review(review)\n",
    "    \n",
    "    print(f\"\\nüìù Review: {review}\\n\")\n",
    "    print(f\"üòäüòû Sentiment: {result['sentiment'].upper()} ({result['sentiment_confidence']:.1%} confident)\")\n",
    "    print(f\"\\nüè∑Ô∏è  Topics Detected:\")\n",
    "    for topic in result['topics']:\n",
    "        print(f\"   - {topic['topic']}: {topic['confidence']:.1%}\")\n",
    "    \n",
    "    print(f\"\\n‚ö° Urgency: {'üö® URGENT' if result['needs_urgent_response'] else '‚úÖ Routine'} ({result['urgency_confidence']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c7fe2",
   "metadata": {},
   "source": [
    "## üìä Part 4: Testing with Real Amazon Reviews\n",
    "\n",
    "Now let's test our system with actual product reviews from Amazon! We'll use the Amazon Polarity dataset which contains millions of real reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Amazon reviews dataset...\")\n",
    "print(\"(First time will download the dataset - may take a moment)\")\n",
    "\n",
    "# Load dataset in streaming mode (efficient for large datasets)\n",
    "dataset = load_dataset(\"amazon_polarity\", split=\"test\", streaming=True)\n",
    "\n",
    "print(\"‚úÖ Dataset loaded!\")\n",
    "print(\"\\nEach review has:\")\n",
    "print(\"  - 'content': the review text\")\n",
    "print(\"  - 'label': 0 = negative, 1 = positive (for comparison with our model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 5 real Amazon reviews\n",
    "num_samples = 5\n",
    "\n",
    "print(f\"Analyzing {num_samples} real Amazon reviews...\\n\")\n",
    "\n",
    "for i, example in enumerate(dataset):\n",
    "    if i >= num_samples:\n",
    "        break\n",
    "    \n",
    "    review_text = example['content']\n",
    "    original_label = \"POSITIVE\" if example['label'] == 1 else \"NEGATIVE\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"AMAZON REVIEW #{i+1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nüìù Original Review (first 300 chars):\")\n",
    "    print(f\"   {review_text[:300]}...\")\n",
    "    print(f\"\\nüè∑Ô∏è  Amazon's Label: {original_label}\")\n",
    "    \n",
    "    # Analyze with our system\n",
    "    analysis = analyze_review(review_text)\n",
    "    \n",
    "    print(f\"\\nü§ñ Our Model's Analysis:\")\n",
    "    print(f\"   Sentiment: {analysis['sentiment'].upper()} ({analysis['sentiment_confidence']:.1%})\")\n",
    "    print(f\"   Topics: {', '.join([t['topic'] for t in analysis['topics']])}\")\n",
    "    print(f\"   Urgency: {'‚ö° URGENT' if analysis['needs_urgent_response'] else '‚úÖ Routine'}\")\n",
    "    \n",
    "    # Check if our model agrees with Amazon's label\n",
    "    our_label = analysis['sentiment'].upper()\n",
    "    match = \"‚úÖ MATCH\" if our_label == original_label else \"‚ùå DIFFERENT\"\n",
    "    print(f\"\\n   {match} - Our model {'agrees' if match == '‚úÖ MATCH' else 'differs'} with Amazon's label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc8d64",
   "metadata": {},
   "source": [
    "## üöÄ Part 5: Building the FastAPI Service\n",
    "\n",
    "Now comes the exciting part - let's make this accessible through an API! This allows other applications to use our review analysis system.\n",
    "\n",
    "### What is FastAPI?\n",
    "\n",
    "FastAPI is a modern Python framework for building APIs. Think of an API as a waiter in a restaurant:\n",
    "- You (the client) make a request (\"I want the sentiment of this review\")\n",
    "- The API (waiter) takes your request to the kitchen (our AI models)\n",
    "- The kitchen prepares your order (analyzes the review)\n",
    "- The waiter brings back the result\n",
    "\n",
    "### Why FastAPI?\n",
    "- ‚ö° **Fast**: Built on modern async Python\n",
    "- üìù **Auto-documentation**: Creates interactive docs automatically\n",
    "- ‚úÖ **Type checking**: Catches errors before they happen\n",
    "- üéØ **Easy to use**: Simple, intuitive syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d807d",
   "metadata": {},
   "source": [
    "### Understanding the API Structure\n",
    "\n",
    "Our API file (`api.py`) has these main components:\n",
    "\n",
    "1. **Model Loading** - Load models once at startup (not for every request)\n",
    "2. **Analysis Functions** - The `analyze_review()` function we built\n",
    "3. **Data Models** - Define the structure of requests and responses using Pydantic\n",
    "4. **Endpoints** - Different URLs that handle different tasks:\n",
    "   - `GET /` - Welcome message\n",
    "   - `GET /health` - Check if the API is running\n",
    "   - `POST /analyze` - Analyze a single review\n",
    "   - `POST /analyze-batch` - Analyze multiple reviews at once\n",
    "\n",
    "Let's look at the key parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89909956",
   "metadata": {},
   "source": [
    "### üìã Step 1: Define Data Models with Pydantic\n",
    "\n",
    "Pydantic models define the \"shape\" of our data. They automatically validate inputs and document our API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Dict\n",
    "\n",
    "# What the client sends us\n",
    "class ReviewRequest(BaseModel):\n",
    "    review_text: str\n",
    "\n",
    "# What we send back\n",
    "class ReviewResponse(BaseModel):\n",
    "    sentiment: str\n",
    "    sentiment_confidence: float\n",
    "    topics: List[Dict[str, float]]\n",
    "    needs_urgent_response: bool\n",
    "    urgency_confidence: float\n",
    "\n",
    "# For batch processing\n",
    "class BatchReviewRequest(BaseModel):\n",
    "    reviews: List[str]\n",
    "\n",
    "print(\"‚úÖ Data models defined!\")\n",
    "print(\"\\nExample ReviewRequest:\")\n",
    "example_request = ReviewRequest(review_text=\"Great product!\")\n",
    "print(f\"   {example_request.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d85451e",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Step 2: Create the FastAPI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "\n",
    "# Create the FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Product Review Intelligence API\",\n",
    "    description=\"Analyze product reviews for sentiment, topics, and urgency\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Root endpoint - welcome message\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\n",
    "        \"message\": \"Product Review Intelligence API\",\n",
    "        \"endpoints\": {\n",
    "            \"/analyze\": \"POST - Analyze a single review\",\n",
    "            \"/analyze-batch\": \"POST - Analyze multiple reviews\",\n",
    "            \"/health\": \"GET - Health check\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Health check endpoint\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\", \"models_loaded\": True}\n",
    "\n",
    "print(\"‚úÖ FastAPI app created!\")\n",
    "print(\"\\nEndpoints defined:\")\n",
    "print(\"  GET  /         - Welcome message\")\n",
    "print(\"  GET  /health   - Health check\")\n",
    "print(\"  POST /analyze  - Analyze single review\")\n",
    "print(\"  POST /analyze-batch - Analyze multiple reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da3ee4",
   "metadata": {},
   "source": [
    "### üîå Step 3: Add the Analysis Endpoints\n",
    "\n",
    "Now let's add endpoints that actually do the work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint to analyze a single review\n",
    "@app.post(\"/analyze\", response_model=ReviewResponse)\n",
    "def analyze_single_review(request: ReviewRequest):\n",
    "    \"\"\"\n",
    "    Analyze a single product review\n",
    "    \n",
    "    Takes a ReviewRequest with review_text\n",
    "    Returns sentiment, topics, and urgency information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not request.review_text or len(request.review_text.strip()) == 0:\n",
    "            raise HTTPException(status_code=400, detail=\"Review text cannot be empty\")\n",
    "        \n",
    "        # Analyze the review\n",
    "        result = analyze_review(request.review_text)\n",
    "        \n",
    "        # Return response\n",
    "        return ReviewResponse(\n",
    "            sentiment=result['sentiment'],\n",
    "            sentiment_confidence=result['sentiment_confidence'],\n",
    "            topics=result['topics'],\n",
    "            needs_urgent_response=result['needs_urgent_response'],\n",
    "            urgency_confidence=result['urgency_confidence']\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Endpoint to analyze multiple reviews at once\n",
    "@app.post(\"/analyze-batch\")\n",
    "def analyze_batch_reviews(request: BatchReviewRequest):\n",
    "    \"\"\"\n",
    "    Analyze multiple product reviews at once\n",
    "    \n",
    "    Maximum 50 reviews per batch\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not request.reviews or len(request.reviews) == 0:\n",
    "            raise HTTPException(status_code=400, detail=\"Reviews list cannot be empty\")\n",
    "        \n",
    "        if len(request.reviews) > 50:\n",
    "            raise HTTPException(status_code=400, detail=\"Maximum 50 reviews per batch\")\n",
    "        \n",
    "        results = []\n",
    "        for review_text in request.reviews:\n",
    "            if review_text and len(review_text.strip()) > 0:\n",
    "                result = analyze_review(review_text)\n",
    "                results.append(result)\n",
    "        \n",
    "        return {\"results\": results, \"count\": len(results)}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "print(\"‚úÖ Analysis endpoints added!\")\n",
    "print(\"\\nNOTE: In a Jupyter notebook, we can't run the server directly.\")\n",
    "print(\"To actually run the API, use the api.py file in a terminal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052bc01",
   "metadata": {},
   "source": [
    "## üéÆ Part 6: How to Run the API\n",
    "\n",
    "### Option 1: Run from Terminal (Recommended)\n",
    "\n",
    "The `api.py` file is ready to use. Open a terminal and run:\n",
    "\n",
    "```bash\n",
    "# Navigate to the directory\n",
    "cd /path/to/Product_Review_Intelligence\n",
    "\n",
    "# Run the API server\n",
    "python api.py\n",
    "```\n",
    "\n",
    "Or use uvicorn directly for more control:\n",
    "\n",
    "```bash\n",
    "uvicorn api:app --host 0.0.0.0 --port 8000 --reload\n",
    "```\n",
    "\n",
    "**Flags explained:**\n",
    "- `--host 0.0.0.0` - Accept connections from any IP\n",
    "- `--port 8000` - Run on port 8000\n",
    "- `--reload` - Auto-restart when code changes (dev only)\n",
    "\n",
    "### Option 2: Background Server (for notebooks)\n",
    "\n",
    "We can start a background server from this notebook for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ee931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def run_server():\n",
    "    \"\"\"Run the API server in a background thread\"\"\"\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"info\")\n",
    "\n",
    "# Start server in background (uncomment to run)\n",
    "# server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "# server_thread.start()\n",
    "# time.sleep(3)  # Wait for server to start\n",
    "# print(\"‚úÖ Server started at http://127.0.0.1:8000\")\n",
    "# print(\"üìö Interactive docs at http://127.0.0.1:8000/docs\")\n",
    "\n",
    "print(\"To start the server, uncomment the lines above and run this cell.\")\n",
    "print(\"\\nFor production use, run the api.py file from terminal instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba838e",
   "metadata": {},
   "source": [
    "## üß™ Part 7: Testing the API\n",
    "\n",
    "Once the server is running, we can test it! Here are several ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d62a1",
   "metadata": {},
   "source": [
    "### Method 1: Using Python Requests Library\n",
    "\n",
    "First, make sure the server is running (in terminal: `python api.py`), then run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7263cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# API endpoint\n",
    "API_URL = \"http://127.0.0.1:8000\"\n",
    "\n",
    "# Test 1: Health check\n",
    "print(\"Testing health endpoint...\")\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/health\")\n",
    "    print(f\"‚úÖ Status: {response.status_code}\")\n",
    "    print(f\"Response: {response.json()}\\n\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Server not running. Start it first with: python api.py\\n\")\n",
    "\n",
    "# Test 2: Analyze a single review\n",
    "print(\"Testing single review analysis...\")\n",
    "try:\n",
    "    review_data = {\n",
    "        \"review_text\": \"Amazing product! Great quality but shipping was a bit slow. Worth the wait though!\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{API_URL}/analyze\", json=review_data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"‚úÖ Status: {response.status_code}\")\n",
    "        print(f\"\\nüìä Analysis Results:\")\n",
    "        print(f\"   Sentiment: {result['sentiment']} ({result['sentiment_confidence']:.1%})\")\n",
    "        print(f\"   Topics: {[t['topic'] for t in result['topics']]}\")\n",
    "        print(f\"   Urgent: {result['needs_urgent_response']}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Server not running. Start it first with: python api.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3dbe5",
   "metadata": {},
   "source": [
    "### Test Batch Processing\n",
    "\n",
    "Analyze multiple reviews at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing batch review analysis...\")\n",
    "\n",
    "try:\n",
    "    batch_data = {\n",
    "        \"reviews\": [\n",
    "            \"Excellent product! Highly recommend.\",\n",
    "            \"Terrible. Broke after one use. Need refund ASAP!\",\n",
    "            \"Average quality for the price.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{API_URL}/analyze-batch\", json=batch_data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"‚úÖ Analyzed {result['count']} reviews\\n\")\n",
    "        \n",
    "        for i, analysis in enumerate(result['results'], 1):\n",
    "            print(f\"Review {i}:\")\n",
    "            print(f\"  Text: {analysis['review_text'][:60]}...\")\n",
    "            print(f\"  Sentiment: {analysis['sentiment']} ({analysis['sentiment_confidence']:.1%})\")\n",
    "            print(f\"  Urgent: {'üö® YES' if analysis['needs_urgent_response'] else '‚úÖ No'}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Server not running. Start it first with: python api.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b44d9",
   "metadata": {},
   "source": [
    "### Method 2: Using cURL (Command Line)\n",
    "\n",
    "You can also test from the terminal using cURL:\n",
    "\n",
    "```bash\n",
    "# Health check\n",
    "curl http://localhost:8000/health\n",
    "\n",
    "# Analyze a single review\n",
    "curl -X POST \"http://localhost:8000/analyze\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"review_text\": \"Great product but shipping took forever!\"}'\n",
    "\n",
    "# Analyze multiple reviews\n",
    "curl -X POST \"http://localhost:8000/analyze-batch\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"reviews\": [\"Amazing!\", \"Terrible product.\"]}'\n",
    "```\n",
    "\n",
    "### Method 3: Interactive API Documentation\n",
    "\n",
    "FastAPI automatically generates interactive documentation!\n",
    "\n",
    "**Once the server is running**, visit:\n",
    "- **Swagger UI**: http://localhost:8000/docs\n",
    "- **ReDoc**: http://localhost:8000/redoc\n",
    "\n",
    "These provide a web interface where you can:\n",
    "- See all endpoints\n",
    "- Read detailed documentation\n",
    "- Test the API interactively\n",
    "- See request/response examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b204ef",
   "metadata": {},
   "source": [
    "## üìö Part 8: Understanding Each Model in Detail\n",
    "\n",
    "Let's dive deeper into how each model works:\n",
    "\n",
    "### Model 1: DistilBERT for Sentiment Analysis\n",
    "\n",
    "**Model Name**: `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "\n",
    "**What is DistilBERT?**\n",
    "- **BERT** (Bidirectional Encoder Representations from Transformers) - A groundbreaking model by Google\n",
    "- **DistilBERT** - A \"distilled\" (compressed) version that's 60% faster and 40% smaller\n",
    "- **Fine-tuned on SST-2** - Stanford Sentiment Treebank v2 (movie reviews)\n",
    "\n",
    "**How it Works:**\n",
    "1. Takes text input\n",
    "2. Converts words to numbers (tokens)\n",
    "3. Processes bidirectionally (reads left‚Üíright AND right‚Üíleft)\n",
    "4. Outputs: POSITIVE or NEGATIVE with confidence score\n",
    "\n",
    "**Why it's good:**\n",
    "- ‚úÖ Fast inference (~30ms per review)\n",
    "- ‚úÖ High accuracy (~91% on SST-2)\n",
    "- ‚úÖ Generalizes well to product reviews\n",
    "- ‚úÖ Small enough to run on CPU\n",
    "\n",
    "**Technical Details:**\n",
    "- Parameters: ~67 million\n",
    "- Max sequence length: 512 tokens\n",
    "- Output: 2 classes (positive/negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e2843",
   "metadata": {},
   "source": [
    "### Model 2: BART for Zero-Shot Classification\n",
    "\n",
    "**Model Name**: `facebook/bart-large-mnli`\n",
    "\n",
    "**What is BART?**\n",
    "- **BART** - Bidirectional and Auto-Regressive Transformer by Facebook/Meta\n",
    "- Combines best of BERT (encoder) and GPT (decoder)\n",
    "- **MNLI** - Multi-Genre Natural Language Inference dataset\n",
    "\n",
    "**What is Zero-Shot Classification?**\n",
    "Zero-shot means the model can classify text into categories it has NEVER seen during training!\n",
    "\n",
    "**How it Works:**\n",
    "1. You provide text: \"Great product but slow shipping\"\n",
    "2. You provide labels: [\"quality\", \"shipping\", \"price\"]\n",
    "3. Model converts this to: \"This text is about ___\" (hypothesis)\n",
    "4. For each label, it checks: \"Does this text imply it's about quality?\" ‚Üí Yes/No probability\n",
    "5. Returns confidence scores for each label\n",
    "\n",
    "**Real Example:**\n",
    "```\n",
    "Text: \"The phone battery lasts all day!\"\n",
    "Labels: [\"battery life\", \"screen quality\", \"price\"]\n",
    "\n",
    "Output:\n",
    "- battery life: 0.95 (95% confident)\n",
    "- screen quality: 0.12 (12% confident)  \n",
    "- price: 0.08 (8% confident)\n",
    "```\n",
    "\n",
    "**Why it's powerful:**\n",
    "- ‚úÖ No retraining needed for new categories\n",
    "- ‚úÖ Can detect multiple topics at once (multi-label)\n",
    "- ‚úÖ Flexible - works for urgency, topics, emotions, anything!\n",
    "- ‚úÖ High accuracy on NLI tasks (~90%)\n",
    "\n",
    "**Technical Details:**\n",
    "- Parameters: ~400 million\n",
    "- Max sequence length: 1024 tokens\n",
    "- Based on Natural Language Inference (NLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf06b8e",
   "metadata": {},
   "source": [
    "## üéØ Part 9: Real-World Use Cases\n",
    "\n",
    "### Use Case 1: E-commerce Platform\n",
    "\n",
    "**Scenario**: You run an online store with 10,000 reviews per day\n",
    "\n",
    "**Solution with our API:**\n",
    "```python\n",
    "# Automatically categorize reviews\n",
    "reviews = get_daily_reviews()  # Your database\n",
    "\n",
    "for review in reviews:\n",
    "    analysis = analyze_review(review.text)\n",
    "    \n",
    "    # Route urgent issues to support team\n",
    "    if analysis['needs_urgent_response']:\n",
    "        notify_support_team(review, analysis)\n",
    "    \n",
    "    # Track sentiment trends\n",
    "    log_sentiment(review.product_id, analysis['sentiment'])\n",
    "    \n",
    "    # Identify product issues\n",
    "    if 'product quality' in [t['topic'] for t in analysis['topics']]:\n",
    "        if analysis['sentiment'] == 'negative':\n",
    "            flag_quality_issue(review.product_id)\n",
    "```\n",
    "\n",
    "### Use Case 2: Customer Service Dashboard\n",
    "\n",
    "Create a real-time dashboard showing:\n",
    "- üìä Sentiment distribution (% positive vs negative)\n",
    "- üî• Hot topics (what customers talk about most)\n",
    "- üö® Urgent reviews requiring immediate attention\n",
    "- üìà Trends over time\n",
    "\n",
    "### Use Case 3: Automated Responses\n",
    "\n",
    "```python\n",
    "analysis = analyze_review(review_text)\n",
    "\n",
    "if analysis['needs_urgent_response'] and analysis['sentiment'] == 'negative':\n",
    "    # Priority 1: Urgent negative review\n",
    "    send_immediate_response(review, priority=1)\n",
    "    assign_to_senior_support()\n",
    "elif analysis['sentiment'] == 'negative':\n",
    "    # Priority 2: Negative review\n",
    "    send_apology_template(review)\n",
    "else:\n",
    "    # Thank positive reviewers\n",
    "    send_thank_you(review)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d9ffa",
   "metadata": {},
   "source": [
    "## üöÄ Part 10: Performance & Optimization Tips\n",
    "\n",
    "### Current Performance\n",
    "\n",
    "**Single Review Analysis:**\n",
    "- Sentiment: ~30ms\n",
    "- Topic Detection: ~200ms\n",
    "- Urgency Detection: ~200ms\n",
    "- **Total**: ~430ms per review\n",
    "\n",
    "**Batch Processing:**\n",
    "- Can analyze 50 reviews in ~20 seconds\n",
    "- Parallel processing would be faster\n",
    "\n",
    "### Optimization Strategies\n",
    "\n",
    "#### 1. Use GPU for Production\n",
    "```python\n",
    "# When loading models\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=0  # Use GPU device 0\n",
    ")\n",
    "```\n",
    "\n",
    "**Impact**: 5-10x faster inference\n",
    "\n",
    "#### 2. Batch Processing\n",
    "```python\n",
    "# Instead of processing one by one\n",
    "results = sentiment_analyzer(list_of_reviews)  # Batch inference\n",
    "```\n",
    "\n",
    "**Impact**: 3-5x faster for large batches\n",
    "\n",
    "#### 3. Model Caching\n",
    "Models are loaded once at startup (already implemented)\n",
    "\n",
    "**Impact**: Saves 2-5 seconds per request\n",
    "\n",
    "#### 4. Async Processing for API\n",
    "```python\n",
    "from fastapi import BackgroundTasks\n",
    "\n",
    "@app.post(\"/analyze-async\")\n",
    "async def analyze_async(request: ReviewRequest, background_tasks: BackgroundTasks):\n",
    "    background_tasks.add_task(analyze_and_store, request.review_text)\n",
    "    return {\"status\": \"processing\"}\n",
    "```\n",
    "\n",
    "**Impact**: Non-blocking API calls\n",
    "\n",
    "#### 5. Use Quantization (Advanced)\n",
    "```python\n",
    "# Reduce model size and increase speed\n",
    "# Requires: optimum library\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "\n",
    "model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    export=True,\n",
    ")\n",
    "```\n",
    "\n",
    "**Impact**: 2-4x faster, 4x smaller model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642fa2f",
   "metadata": {},
   "source": [
    "## üéì Part 11: Key Concepts Summary\n",
    "\n",
    "### What We Built\n",
    "\n",
    "A **Product Review Intelligence System** that:\n",
    "1. ‚úÖ Analyzes sentiment (positive/negative)\n",
    "2. ‚úÖ Detects topics (quality, shipping, price, etc.)\n",
    "3. ‚úÖ Identifies urgent reviews\n",
    "4. ‚úÖ Provides REST API for easy integration\n",
    "5. ‚úÖ Tested with real Amazon reviews\n",
    "\n",
    "### Key Technologies\n",
    "\n",
    "| Technology | Purpose | Why We Use It |\n",
    "|------------|---------|---------------|\n",
    "| **Transformers** | Pre-trained AI models | Access to state-of-the-art models |\n",
    "| **DistilBERT** | Sentiment analysis | Fast, accurate, efficient |\n",
    "| **BART** | Zero-shot classification | Flexible topic detection |\n",
    "| **FastAPI** | Web API framework | Modern, fast, auto-documentation |\n",
    "| **Uvicorn** | ASGI server | Run FastAPI applications |\n",
    "| **Pydantic** | Data validation | Type-safe request/response |\n",
    "\n",
    "### How the Pipeline Works\n",
    "\n",
    "```\n",
    "User Review Text\n",
    "       ‚Üì\n",
    "1. Text Preprocessing (truncate to 512 tokens)\n",
    "       ‚Üì\n",
    "2. Sentiment Analysis (DistilBERT)\n",
    "   ‚Üí Positive/Negative + Confidence\n",
    "       ‚Üì\n",
    "3. Topic Classification (BART Zero-Shot)\n",
    "   ‚Üí Quality, Shipping, Price, etc.\n",
    "       ‚Üì\n",
    "4. Urgency Detection (BART Zero-Shot)\n",
    "   ‚Üí Urgent/Routine + Confidence\n",
    "       ‚Üì\n",
    "5. Return Combined Results (JSON)\n",
    "```\n",
    "\n",
    "### Important Parameters Explained\n",
    "\n",
    "**`multi_label=True` vs `multi_label=False`**\n",
    "- `True`: Multiple labels can be correct (topics: quality AND shipping)\n",
    "- `False`: Only one label is correct (urgency: urgent OR routine)\n",
    "\n",
    "**Confidence Threshold (0.5)**\n",
    "- We filter topics with confidence > 50%\n",
    "- Lower threshold = more topics detected (but less accurate)\n",
    "- Higher threshold = fewer topics (but more confident)\n",
    "\n",
    "**Model Truncation (512 tokens)**\n",
    "- DistilBERT max: 512 tokens (~380 words)\n",
    "- BART max: 1024 tokens (~770 words)\n",
    "- We use 512 for consistency and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43805a",
   "metadata": {},
   "source": [
    "## üí° Part 12: Extending the System\n",
    "\n",
    "### Idea 1: Add More Topics\n",
    "\n",
    "You can easily add new topics to detect:\n",
    "\n",
    "```python\n",
    "TOPICS = [\n",
    "    \"product quality\",\n",
    "    \"shipping and delivery\",\n",
    "    \"price and value\",\n",
    "    \"customer service\",\n",
    "    \"packaging\",\n",
    "    # Add your own!\n",
    "    \"durability\",\n",
    "    \"ease of use\",\n",
    "    \"design and appearance\",\n",
    "    \"size and fit\",\n",
    "    \"warranty and returns\"\n",
    "]\n",
    "```\n",
    "\n",
    "### Idea 2: Multi-language Support\n",
    "\n",
    "Use multilingual models:\n",
    "\n",
    "```python\n",
    "# Replace with multilingual model\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    ")\n",
    "```\n",
    "\n",
    "Supports: English, Spanish, French, German, Italian, Dutch\n",
    "\n",
    "### Idea 3: Emotion Detection\n",
    "\n",
    "Instead of just positive/negative, detect specific emotions:\n",
    "\n",
    "```python\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"bhadresh-savani/distilbert-base-uncased-emotion\"\n",
    ")\n",
    "\n",
    "# Detects: joy, sadness, anger, fear, love, surprise\n",
    "```\n",
    "\n",
    "### Idea 4: Save Results to Database\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "\n",
    "def save_analysis(review_id, analysis):\n",
    "    conn = sqlite3.connect('reviews.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "        INSERT INTO analyses (review_id, sentiment, urgency, topics)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    ''', (\n",
    "        review_id,\n",
    "        analysis['sentiment'],\n",
    "        analysis['needs_urgent_response'],\n",
    "        json.dumps(analysis['topics'])\n",
    "    ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "### Idea 5: Add Authentication\n",
    "\n",
    "```python\n",
    "from fastapi import Depends, HTTPException\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "\n",
    "security = HTTPBearer()\n",
    "\n",
    "def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "    if credentials.credentials != \"your-secret-token\":\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid token\")\n",
    "    return credentials.credentials\n",
    "\n",
    "@app.post(\"/analyze\", dependencies=[Depends(verify_token)])\n",
    "def analyze_single_review(request: ReviewRequest):\n",
    "    # Only accessible with valid token\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e8cc5",
   "metadata": {},
   "source": [
    "## üêõ Part 13: Common Issues & Solutions\n",
    "\n",
    "### Issue 1: \"Models are too slow\"\n",
    "\n",
    "**Solutions:**\n",
    "1. Use GPU: `device=0` in pipeline creation\n",
    "2. Use smaller models: Try `distilbert` variants\n",
    "3. Reduce batch size if running out of memory\n",
    "4. Consider model quantization\n",
    "\n",
    "### Issue 2: \"Out of memory error\"\n",
    "\n",
    "**Solutions:**\n",
    "```python\n",
    "# Process in smaller batches\n",
    "def analyze_large_batch(reviews, batch_size=10):\n",
    "    results = []\n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        batch = reviews[i:i+batch_size]\n",
    "        results.extend([analyze_review(r) for r in batch])\n",
    "    return results\n",
    "```\n",
    "\n",
    "### Issue 3: \"Wrong sentiment detected\"\n",
    "\n",
    "**Causes:**\n",
    "- Sarcasm (models struggle with this)\n",
    "- Mixed sentiment reviews\n",
    "- Domain-specific language\n",
    "\n",
    "**Solutions:**\n",
    "- Use domain-specific models (e.g., models trained on product reviews)\n",
    "- Fine-tune on your own data\n",
    "- Implement manual review for low-confidence predictions\n",
    "\n",
    "### Issue 4: \"API returns 500 error\"\n",
    "\n",
    "**Debug:**\n",
    "```python\n",
    "# Add detailed error logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "@app.post(\"/analyze\")\n",
    "def analyze_single_review(request: ReviewRequest):\n",
    "    try:\n",
    "        result = analyze_review(request.review_text)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error analyzing review: {str(e)}\", exc_info=True)\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "```\n",
    "\n",
    "### Issue 5: \"Models won't download\"\n",
    "\n",
    "**Solutions:**\n",
    "```python\n",
    "# Set cache directory\n",
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/path/to/cache'\n",
    "\n",
    "# Or download manually\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3135121",
   "metadata": {},
   "source": [
    "## üìñ Part 14: Additional Resources & Learning\n",
    "\n",
    "### Learn More About Transformers\n",
    "\n",
    "**Official Documentation:**\n",
    "- Hugging Face Docs: https://huggingface.co/docs/transformers\n",
    "- Model Hub: https://huggingface.co/models\n",
    "- FastAPI Docs: https://fastapi.tiangolo.com\n",
    "\n",
    "### Recommended Models to Try\n",
    "\n",
    "**Sentiment Analysis:**\n",
    "- `cardiffnlp/twitter-roberta-base-sentiment` - Great for social media\n",
    "- `nlptown/bert-base-multilingual-uncased-sentiment` - Multi-language, 5-star ratings\n",
    "- `ProsusAI/finbert` - Financial sentiment\n",
    "\n",
    "**Topic Classification:**\n",
    "- `facebook/bart-large-mnli` - (What we use)\n",
    "- `MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli` - More accurate\n",
    "- `valhalla/distilbart-mnli-12-1` - Faster, smaller\n",
    "\n",
    "**Emotion Detection:**\n",
    "- `bhadresh-savani/distilbert-base-uncased-emotion` - 6 emotions\n",
    "- `j-hartmann/emotion-english-distilroberta-base` - 7 emotions\n",
    "\n",
    "### Books & Courses\n",
    "\n",
    "1. **\"Natural Language Processing with Transformers\"** by Lewis Tunstall\n",
    "2. **Hugging Face Course** (Free): https://huggingface.co/course\n",
    "3. **FastAPI Tutorial**: https://fastapi.tiangolo.com/tutorial/\n",
    "\n",
    "### Join the Community\n",
    "\n",
    "- Hugging Face Forums: https://discuss.huggingface.co\n",
    "- FastAPI Discord: https://discord.gg/fastapi\n",
    "- Reddit: r/MachineLearning, r/LanguageTechnology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e369d8",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "Congratulations! You now understand:\n",
    "\n",
    "‚úÖ **How AI models work** - Pre-trained transformers, sentiment analysis, zero-shot classification  \n",
    "‚úÖ **How to use Hugging Face** - Loading models, pipelines, inference  \n",
    "‚úÖ **How to build APIs** - FastAPI, endpoints, request/response models  \n",
    "‚úÖ **Real-world application** - Processing actual Amazon reviews  \n",
    "‚úÖ **Production considerations** - Performance, error handling, scaling  \n",
    "\n",
    "### The Complete Workflow\n",
    "\n",
    "```\n",
    "Business Problem: Analyze 1000s of reviews manually\n",
    "              ‚Üì\n",
    "Solution: AI-powered automation\n",
    "              ‚Üì\n",
    "1. Load pre-trained models (DistilBERT + BART)\n",
    "2. Build analysis pipeline (sentiment + topics + urgency)\n",
    "3. Wrap in REST API (FastAPI)\n",
    "4. Test with real data (Amazon reviews)\n",
    "5. Deploy & integrate (your application)\n",
    "              ‚Üì\n",
    "Result: Instant review analysis at scale!\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Run the API**: `python api.py`\n",
    "2. **Test it**: Try the interactive docs at `/docs`\n",
    "3. **Customize**: Add your own topics and categories\n",
    "4. **Integrate**: Connect to your application\n",
    "5. **Scale**: Deploy to production (Docker, cloud)\n",
    "\n",
    "### Files in This Project\n",
    "\n",
    "- üìì `Product_Review.ipynb` - This notebook (learning & experimentation)\n",
    "- üêç `api.py` - Production-ready API code\n",
    "- üì¶ `requirements.txt` - All dependencies\n",
    "- üìñ `README.md` - Project documentation\n",
    "\n",
    "---\n",
    "\n",
    "### üôè Thank You!\n",
    "\n",
    "You now have a powerful, production-ready review analysis system. Feel free to:\n",
    "- Modify the models\n",
    "- Add new features\n",
    "- Scale to millions of reviews\n",
    "- Build amazing products!\n",
    "\n",
    "**Happy coding! üöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d76fe",
   "metadata": {},
   "source": [
    "## üß™ Bonus: Interactive Playground\n",
    "\n",
    "Try your own reviews here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c59415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéÆ INTERACTIVE PLAYGROUND\n",
    "# Change the review text below and run this cell to analyze it!\n",
    "\n",
    "your_review = \"\"\"\n",
    "This laptop is fantastic! The battery life is incredible - lasts all day. \n",
    "However, the shipping took 3 weeks which was frustrating. \n",
    "The packaging was damaged when it arrived. \n",
    "Overall, I'm happy with the product quality but disappointed with the delivery experience.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç ANALYZING YOUR REVIEW...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "result = analyze_review(your_review.strip())\n",
    "\n",
    "print(f\"\\nüìù Review:\")\n",
    "print(f\"   {your_review.strip()}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"üòäüòû SENTIMENT: {result['sentiment'].upper()}\")\n",
    "print(f\"   Confidence: {result['sentiment_confidence']:.1%}\")\n",
    "print(f\"   {('Very confident!' if result['sentiment_confidence'] > 0.9 else 'Moderately confident' if result['sentiment_confidence'] > 0.7 else 'Low confidence')}\\n\")\n",
    "\n",
    "print(f\"üè∑Ô∏è  TOPICS DETECTED:\")\n",
    "if result['topics']:\n",
    "    for topic in result['topics']:\n",
    "        bar = \"‚ñà\" * int(topic['confidence'] * 30)\n",
    "        print(f\"   {topic['topic']:25} {topic['confidence']:.1%} {bar}\")\n",
    "else:\n",
    "    print(\"   No strong topics detected (all below 50% confidence)\")\n",
    "\n",
    "print(f\"\\n‚ö° URGENCY:\")\n",
    "print(f\"   Status: {'üö® URGENT - Needs immediate attention!' if result['needs_urgent_response'] else '‚úÖ Routine - Can be handled normally'}\")\n",
    "print(f\"   Confidence: {result['urgency_confidence']:.1%}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Suggested action\n",
    "if result['needs_urgent_response'] and result['sentiment'] == 'negative':\n",
    "    print(\"üíº SUGGESTED ACTION: Priority response required!\")\n",
    "    print(\"   - Assign to senior support team\")\n",
    "    print(\"   - Respond within 4 hours\")\n",
    "    print(\"   - Offer compensation if appropriate\")\n",
    "elif result['sentiment'] == 'negative':\n",
    "    print(\"üíº SUGGESTED ACTION: Address customer concerns\")\n",
    "    print(\"   - Send apology and explanation\")\n",
    "    print(\"   - Respond within 24 hours\")\n",
    "    print(\"   - Offer solution or alternative\")\n",
    "elif result['sentiment'] == 'positive':\n",
    "    print(\"üíº SUGGESTED ACTION: Engage positive customer\")\n",
    "    print(\"   - Send thank you message\")\n",
    "    print(\"   - Request detailed review/testimonial\")\n",
    "    print(\"   - Offer loyalty discount\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"\\n‚úèÔ∏è  Try changing 'your_review' above and run again!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
